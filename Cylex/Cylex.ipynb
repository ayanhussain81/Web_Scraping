{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b3f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests,time,csv\n",
    "import urllib.parse\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de498369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parsed_url(substr):\n",
    "    parts = substr.split(\"&&&\")\n",
    "    category, location, district = parts[0], parts[1], parts[2]\n",
    "    return category, location, district\n",
    "\n",
    "def parsed_number(num):  \n",
    "    faxx,phonee=[],[]\n",
    "    for data in num:\n",
    "        if 'Phone' in data:\n",
    "            extra = data.split(':')\n",
    "            phonee.append(extra[1])\n",
    "        elif 'Mobile' in data:\n",
    "            extra=data.split(':')\n",
    "            phonee.append(extra[1])\n",
    "        elif 'Fax' in data:\n",
    "            extra=data.split(':')\n",
    "            faxx.append(extra[1])\n",
    "        else:\n",
    "            phonee.append(num[0])\n",
    "            try: \n",
    "                faxx.append(num[1])\n",
    "            except:\n",
    "                pass\n",
    "            break\n",
    "    return phonee,faxx\n",
    "\n",
    "\n",
    "with open('------------------.csv','a', encoding= 'utf8' ,newline='') as f:\n",
    "    thewriter = writer(f)\n",
    "#     header= [\"Category\",\"City\",\"District\",\"Link\",\"Name\", \"Address\",\"Phone\",\"Fax\",\"Website\",\"Email\",\"Description\"]\n",
    "#     thewriter.writerow(header)\n",
    "    with open('----------------------', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for count, row in enumerate(reader):\n",
    "            for string in row:\n",
    "                category, location, district ='','',''\n",
    "                substrings = string.split('joining')\n",
    "                url = substrings[0]\n",
    "                category, location, district =parsed_url(substrings[1])\n",
    "                print(url,count)\n",
    "                sa_key = '475004445dc448db8bc870f4b1f61863'\n",
    "                sa_api = 'https://api.scrapingant.com/v2/general'\n",
    "                qParams = {'url': url, 'x-api-key': sa_key}\n",
    "                reqUrl = f'{sa_api}?{urllib.parse.urlencode(qParams)}'\n",
    "                r = requests.get(reqUrl)\n",
    "                soup = BeautifulSoup(r.content, 'html.parser')\n",
    "                name,add,web,email= '','','',''\n",
    "                phone,des,number= [],[],[]\n",
    "                try:\n",
    "                    name = soup.find(id='cntct-name').text\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    add = soup.find(id='cp-street').text\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    webb = soup.find(id='cp-website').text\n",
    "                    if 'Website' in webb:\n",
    "                        words = webb.split()\n",
    "                        web = words[1]\n",
    "                    else:\n",
    "                        web = webb\n",
    "                except:\n",
    "                    pass\n",
    "                try: \n",
    "                    phone_no = soup.find(id='cp-mainPhone-1').text\n",
    "                    number.append(phone_no)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    fax = soup.find(id='cp-mainPhone-2').text\n",
    "                    number.append(fax)\n",
    "                except:\n",
    "                    pass\n",
    "                phone,fax = parsed_number(number)\n",
    "\n",
    "                try:\n",
    "                    div_email =soup.find('div', class_='col-sm-10 col-9 contact-data-container').text\n",
    "                    if '@' in div_email:\n",
    "                        email = div_email\n",
    "                except:\n",
    "                    pass\n",
    "                try: \n",
    "                    desc = soup.find(id='ulkw')\n",
    "                    li = desc.find_all('li')\n",
    "                    for i in li:\n",
    "                        des.append(i.text)\n",
    "                except:\n",
    "                    pass\n",
    "                info = [category, location, district,url,name,add,phone,fax,web,email,des]\n",
    "                print(info)\n",
    "                thewriter.writerow(info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf9cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
